{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback, TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random, sys, io, re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length:  58\n",
      "min length:  46\n"
     ]
    }
   ],
   "source": [
    "shakes_lines = []\n",
    "poem_starts = []\n",
    "next_ln = False\n",
    "min_ = 100\n",
    "\n",
    "with open(\"data/shakespeare.txt\") as f:\n",
    "    \n",
    "    # Read in all lines\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        \n",
    "        # replace poem breaks with ~\n",
    "        if re.match('\\s+\\d+', line):\n",
    "            shakes_lines.append('~')\n",
    "            next_ln = True\n",
    "            continue\n",
    "            \n",
    "        # get rid of blank lines\n",
    "        seq = line.strip()\n",
    "        if len(seq) < 3:\n",
    "            continue\n",
    "        else:\n",
    "            min_ = len(seq)\n",
    "        # remove punctuation\n",
    "        seq = seq.translate(str.maketrans('', '', string.punctuation))\n",
    "        # make lowercase\n",
    "        seq = seq.lower()\n",
    "        #print(seq)\n",
    "        shakes_lines.append(seq)\n",
    "        \n",
    "        if next_ln:\n",
    "            poem_starts.append(seq)\n",
    "    \n",
    "processed_text = '\\n'.join(shakes_lines)\n",
    "# print(processed_text[:60*20])\n",
    "# print(poem_starts[:5])\n",
    "\n",
    "maxlen = max([len(ln) for ln in processed_text.split('\\n')]) + 1\n",
    "print('max length: ', maxlen)\n",
    "print('min length: ', min_)\n",
    "\n",
    "window_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 29\n",
      "['\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(processed_text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "char_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 30268\n",
      "Vectorization...\n",
      "(30268, 40, 29) (30268, 29)\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of window_size characters\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(processed_text) - window_size, step):\n",
    "    sentences.append(processed_text[i: i + window_size])\n",
    "    next_chars.append(processed_text[i + window_size])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), window_size, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        try:\n",
    "            x[i, t, char_index[char]] = 1\n",
    "        except:\n",
    "            print(i, t, char_index[char])\n",
    "    y[i, char_index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(window_size, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(clipnorm=1)\n",
    "model.compile(optimizer, 'categorical_crossentropy', \n",
    "              metrics=['categorical_accuracy', 'categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(from_seed, temp=0.5, fast=True):\n",
    "    print(f'-- Generating Poem With Temperature: {temp}')\n",
    "\n",
    "    generated = ''\n",
    "    sentence = from_seed\n",
    "    generated += sentence\n",
    "    \n",
    "    real_start = from_seed[len(from_seed) - len(from_seed.lstrip()):]\n",
    "    print(f'-- From seed: \\n\\\"{real_start}\\\"\\n')\n",
    "    \n",
    "    if not fast:\n",
    "        sys.stdout.write(real_start)\n",
    "\n",
    "    lines = 1\n",
    "    if not fast:\n",
    "        while lines < 14:\n",
    "            x_pred = np.zeros((1, window_size, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_index[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, temp)\n",
    "            next_char = index_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            if not fast:\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            generated += next_char\n",
    "            lines = len(generated.split('\\n'))\n",
    "    else:\n",
    "        for _ in range(300):\n",
    "            x_pred = np.zeros((1, window_size, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_index[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, temp)\n",
    "            next_char = index_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            if not fast:\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            generated += next_char\n",
    "            lines = len(generated.split('\\n'))\n",
    "        \n",
    "    if fast:\n",
    "        print(generated)\n",
    "    else:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _, epochs_split=5):\n",
    "    if epoch % epochs_split == 0:\n",
    "        \n",
    "        start_index = random.randint(0, len(processed_text) - window_size - 1)\n",
    "        for temp in [0.2, 0.5, 1.0]:\n",
    "\n",
    "            sentence = processed_text[start_index: start_index + window_size]\n",
    "            generate_poem(sentence, temp=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "30268/30268 [==============================] - 5s 162us/step - loss: 2.4253 - categorical_accuracy: 0.3024 - categorical_crossentropy: 2.4253\n",
      "-- Generating Poem With Temperature: 0.2\n",
      "-- From seed: \n",
      "\"my passion\n",
      "a womans gentle heart but no\"\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-72972ea1f100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=[print_callback])#, tensorboard])\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-88830e0d1af0>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(epoch, _, epochs_split)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mgenerate_poem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-175-af1067d64059>\u001b[0m in \u001b[0;36mgenerate_poem\u001b[0;34m(from_seed, temp, fast)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-b8fdc417e259>\u001b[0m in \u001b[0;36msample\u001b[0;34m(preds, temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# helper function to sample an index from a probability array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexp_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])#, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generating Poem With Temperature: 0.25\n",
      "-- From seed: \n",
      "\"will be a tattered weed of small worth held\"\n",
      "\n",
      "will be a tattered weed of small worth held conting make\n",
      "whore in the elower and give anceet freek\n",
      "thou art beauty see noo the cally thes from there is thee with seef in my boonts cantrit\n",
      "by all awrell from the eer lave your seef your deeds the eputter paides sind lie disprite\n",
      "to tenf stiove gover sweet the looke grien\n",
      "that hes precesure thought is shall and your seed\n",
      "~\n",
      "what deam the beauty though is my govent\n",
      "and to be i mave that for my same coont toull\n",
      "wooll be a cartrration shore part\n",
      "the of thy seve that wild do hiverres preek\n",
      "brione seenk love from thy thy sime of thy prigg\n",
      "and will no sweet striegh that love that from thee sweet\n",
      "\n",
      "-- Generating Poem With Temperature: 0.5\n",
      "-- From seed: \n",
      "\"will be a tattered weed of small worth held\"\n",
      "\n",
      "will be a tattered weed of small worth held is and prace\n",
      "perp thou and they fair a pover yel\n",
      "in the gouds sumel sunge my dessace cance\n",
      "and thou broch that renfing thy friss of mestress\n",
      "beat thee\n",
      "tho ess of chrave a do doth deathr spet\n",
      "o to deap ofe love is ard veirtlell with neef\n",
      "in is thou presich dear heath thou ase both\n",
      "is that chowes bred that why thought\n",
      "int with thought is some is strert\n",
      "tho efr beart hark when who you hes sine mine dearts\n",
      "so i with that fen my foult resset thee\n",
      "it the sould i love that which i for ast thee\n",
      "\n",
      "-- Generating Poem With Temperature: 0.75\n",
      "-- From seed: \n",
      "\"will be a tattered weed of small worth held\"\n",
      "\n",
      "will be a tattered weed of small worth held beautyed with yee\n",
      "fromnd sommoll chilt de thu fraiste of sube\n",
      "whon i he bartarass bo but a ame\n",
      "weene by though mine atriving praig\n",
      "~\n",
      "whor and a compowned on bethers ame offerssebe\n",
      "that i ancesure of sweet to love they dowe\n",
      "that vesure of mort farse from thee thou ree\n",
      "dest bat shall this aw yot berouster\n",
      "in theall not with yet sweet which ill loe\n",
      "~\n",
      "thy fare shall thate and proud heart thy drack\n",
      "my ming seen subkll seid doth cancteray thy ull\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = poem_starts[3]\n",
    "prompt = (window_size - len(prompt)) * ' ' + prompt\n",
    "\n",
    "#print(prompt)\n",
    "\n",
    "for t in [0.25, 0.5, 0.75]:\n",
    "    generate_poem(prompt, temp=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
