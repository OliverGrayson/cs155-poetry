{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, random, sys, io, re, string\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakes_lines = []\n",
    "poem_starts = []\n",
    "next_ln = False\n",
    "min_ = 100\n",
    "\n",
    "with open(\"data/shakespeare.txt\") as f:\n",
    "    \n",
    "    # Read in all lines\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        \n",
    "        # replace poem breaks with ~\n",
    "        if re.match('\\s+\\d+', line):\n",
    "            shakes_lines.append('\\n')\n",
    "            next_ln = True\n",
    "            continue\n",
    "            \n",
    "        # get rid of blank lines\n",
    "        seq = line.strip()\n",
    "        if len(seq) < 3:\n",
    "            continue\n",
    "        else:\n",
    "            min_ = len(seq)\n",
    "        # remove punctuation\n",
    "        seq = seq.translate(str.maketrans('', '', string.punctuation))\n",
    "        # make lowercase\n",
    "        seq = seq.lower()\n",
    "        #print(seq)\n",
    "        shakes_lines.append(seq)\n",
    "        \n",
    "        if next_ln:\n",
    "            poem_starts.append(seq)\n",
    "            next_ln = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spens_lines = []\n",
    "pstarts = []\n",
    "\n",
    "with open(\"data/spenser.txt\") as f:\n",
    "    \n",
    "    # Read in all lines\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        \n",
    "        # replace poem breaks with ~\n",
    "        if re.match('(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})\\n', line):\n",
    "            spens_lines.append('\\n')\n",
    "            next_ln = True\n",
    "            continue\n",
    "            \n",
    "        # get rid of blank lines\n",
    "        seq = line.strip()\n",
    "        if len(seq) < 3:\n",
    "            continue\n",
    "        else:\n",
    "            min_ = len(seq)\n",
    "        # remove punctuation\n",
    "        seq = seq.translate(str.maketrans('', '', string.punctuation))\n",
    "        # make lowercase\n",
    "        seq = seq.lower()\n",
    "        #print(seq)\n",
    "        spens_lines.append(seq)\n",
    "        \n",
    "        if next_ln:\n",
    "            pstarts.append(seq)\n",
    "            next_ln = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max line length:  58\n",
      "min line length:  46\n"
     ]
    }
   ],
   "source": [
    "processed_text = ' @ '.join(shakes_lines).replace(' @\\n @', '\\n')\\\n",
    "                 + ' @ '.join(spens_lines[:-1]).replace(' @\\n @\\n @\\n @', '\\n')\n",
    "# print(processed_text[:60*20])\n",
    "# print(poem_starts[:5])\n",
    "\n",
    "poems = processed_text.split('~')\n",
    "maxlen = max([len(ln) for ln in shakes_lines]) + 1\n",
    "print('max line length: ', maxlen)\n",
    "print('min line length: ', min_)\n",
    "#print(poems[:2])\n",
    "\n",
    "#print('total words', len(set(processed_text.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data/processed_shakespeare.txt'\n",
    "vocab_size = 1000\n",
    "\n",
    "with open(fn, 'w') as f:\n",
    "    f.write(processed_text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bit kind of abuses SentencePiece's representation system a bit - it is designed to handle \"one sentence per line\" in the input, so I've modified the prepreprocessing to regard a poem as a \"sentence\" (i.e. one poem per line of input) with the line breaks in the poem converted to the @ symbol, which is made a user-defined symbol in the SentencePiece training so it will never become part of the representation of any other subword. We can convert back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(f\"--input={fn} --model_prefix=m --user_defined_symbols='<n>','@' --vocab_size={vocab_size} --model_type=bpe --pad_id=3\")\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')\n",
    "\n",
    "#sp.encode_as_pieces(poems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "ok\n",
      "985\n",
      "7\n",
      "0\n",
      "<unk> False\n",
      "<s> True\n",
      "</s> True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# returns vocab size\n",
    "print(sp.get_piece_size())\n",
    "\n",
    "# id <=> piece conversion\n",
    "print(sp.id_to_piece(209))\n",
    "print(sp.piece_to_id('@'))\n",
    "print(sp.piece_to_id('▁@'))\n",
    "\n",
    "# returns 0 for unknown tokens (we can change the id for UNK)\n",
    "print(sp.piece_to_id('__MUST_BE_UNKNOWN__'))\n",
    "\n",
    "# <unk>, <s>, </s> are defined by default. Their ids are (0, 1, 2)\n",
    "# <s> and </s> are defined as 'control' symbol.\n",
    "for id in range(3):\n",
    "  print(sp.id_to_piece(id), sp.is_control(id))\n",
    "\n",
    "sp.pad_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fairest creatures we desire increase @ that thereby beautys rose might never die @ but as the riper should by time decease @ his tender heir might bear his memory @ but thou contracted to thine own bright eyes @ feedst thy lights flame with selfsubstantial fuel @ making a famine where abundance lies @ thy self thy foe to thy sweet self too cruel @ thou that art now the worlds fresh ornament @ and only herald to the gaudy spring @ within thine own bud buriest thy content @ and tender churl makst waste in niggarding @ pity the world or else this glutton be @ to eat the worlds due by the grave and thee @ \n",
      "['▁from', '▁fairest', '▁cre', 'ature', 's', '▁we', '▁desire', '▁inc', 'rea', 'se', '▁@', '▁that', '▁there', 'b', 'y', '▁beautys', '▁ro', 'se', '▁might', '▁never', '▁die', '▁@', '▁but', '▁as', '▁the', '▁ri', 'p', 'er', '▁should', '▁by', '▁time', '▁dec', 'ease', '▁@', '▁his', '▁tend', 'er', '▁he', 'ir', '▁might', '▁bear', '▁his', '▁mem', 'ory', '▁@', '▁but', '▁thou', '▁cont', 'ra', 'ct', 'ed', '▁to', '▁thine', '▁own', '▁bright', '▁eyes', '▁@', '▁fe', 'ed', 'st', '▁thy', '▁light', 's', '▁fl', 'ame', '▁with', '▁self', 'su', 'b', 'st', 'ant', 'ial', '▁f', 'u', 'el', '▁@', '▁making', '▁a', '▁fa', 'm', 'ine', '▁where', '▁ab', 'u', 'nd', 'ance', '▁lies', '▁@', '▁thy', '▁self', '▁thy', '▁fo', 'e', '▁to', '▁thy', '▁sweet', '▁self', '▁too', '▁cruel', '▁@', '▁thou', '▁that', '▁art', '▁now', '▁the', '▁worlds', '▁fresh', '▁or', 'na', 'ment', '▁@', '▁and', '▁only', '▁her', 'a', 'ld', '▁to', '▁the', '▁ga', 'u', 'dy', '▁spring', '▁@', '▁within', '▁thine', '▁own', '▁bu', 'd', '▁bu', 'ri', 'est', '▁thy', '▁cont', 'ent', '▁@', '▁and', '▁tend', 'er', '▁ch', 'ur', 'l', '▁mak', 'st', '▁w', 'aste', '▁in', '▁n', 'ig', 'g', 'ard', 'ing', '▁@', '▁pity', '▁the', '▁world', '▁or', '▁else', '▁this', '▁gl', 'ut', 't', 'on', '▁be', '▁@', '▁to', '▁ea', 't', '▁the', '▁worlds', '▁due', '▁by', '▁the', '▁gra', 've', '▁and', '▁thee', '▁@']\n",
      "len of data is (39355, 20) (39355,)\n",
      "Encoding...\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of window_size Sentence Pieces\n",
    "spec = np.array(processed_text.split('\\n'))\n",
    "\n",
    "print(spec[0])\n",
    "print(sp.encode_as_pieces(spec[0]))\n",
    "\n",
    "spec = [sp.encode_as_ids(str(p)) for p in spec]\n",
    "\n",
    "# reduced step size from 3 to 1 because the model now learns by word pieces instead of chars\n",
    "# so stepping by 3 usually goes all the way to the next word\n",
    "step = 1\n",
    "window_size = 20\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# do it this way so training data does not cross poem boundaries\n",
    "for poem in spec:\n",
    "    for i in range(0, len(poem)-window_size, step):\n",
    "        X.append(poem[i:i+window_size])\n",
    "        y.append(poem[i+window_size])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "print('len of data is', X.shape, y.shape)\n",
    "print('Encoding...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def number_to_text(s):\n",
    "    return ''.join(sp.id_to_piece(int(i)) for i in s)\n",
    "\n",
    "def generate_seq(seed, n_pieces=50, temperature=1.0, use_sample=False):\n",
    "    \n",
    "    def reverse_formatting(s):\n",
    "        return s.replace('▁', ' ').replace('@', '\\n').replace('<n>', '')\n",
    "    \n",
    "    in_text = seed.copy()\n",
    "    result = ''\n",
    "    for _ in range(n_pieces):\n",
    "        yhat = model.predict(np.array([in_text[-window_size:]]), verbose=0)\n",
    "        yy = sample(yhat[0], temperature)\n",
    "        \n",
    "        if yy != 0:\n",
    "            in_text.append(yy)\n",
    "            result += (number_to_text([yy]))\n",
    "        \n",
    "    r_seed = reverse_formatting(number_to_text(seed))\n",
    "    print('seed: ' + r_seed)\n",
    "    print('temperature:', temperature)\n",
    "    print('generated:\\n' + r_seed + reverse_formatting(result), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 20, 256)           256000    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 1024)              3149824   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              1025000   \n",
      "=================================================================\n",
      "Total params: 4,430,824\n",
      "Trainable params: 4,430,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Bidirectional, LSTM, Dense, Dropout, Embedding\n",
    "#from keras.optimizers import Adam\n",
    "# tfa's LazyAdam is used because it is supposed to be more efficient for sparse\n",
    "# data. since we are using our own word vectors from the embedding layer this\n",
    "# should yield better results\n",
    "from tensorflow_addons.optimizers import LazyAdam\n",
    "from keras import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "units = 512\n",
    "\n",
    "input_ = Input(shape=(window_size,))\n",
    "\n",
    "emb = Embedding(vocab_size, units//2, input_length=window_size, \n",
    "                mask_zero=True, activity_regularizer=l2(1e-4))(input_)\n",
    "\n",
    "bidirectional = Bidirectional(LSTM(units, activation='relu', recurrent_dropout=0.1,\n",
    "                                   activity_regularizer=l2(1e-4)))(emb)\n",
    "\n",
    "predictor = Dense(vocab_size, activation='softmax', \n",
    "                  activity_regularizer=l2(1e-4))(bidirectional)\n",
    "\n",
    "model = Model(inputs=input_, outputs=predictor)\n",
    "optimizer = LazyAdam(clipnorm=1)\n",
    "model.compile(optimizer, 'sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_crossentropy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 6.2279 - sparse_categorical_crossentropy: 6.1007\n",
      "Epoch 2/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 5.9160 - sparse_categorical_crossentropy: 5.8299\n",
      "Epoch 3/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 5.6680 - sparse_categorical_crossentropy: 5.5477\n",
      "Epoch 4/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 5.4880 - sparse_categorical_crossentropy: 5.3583\n",
      "Epoch 5/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 5.3565 - sparse_categorical_crossentropy: 5.2172\n",
      "Epoch 6/250\n",
      "39355/39355 [==============================] - 87s 2ms/step - loss: 5.2678 - sparse_categorical_crossentropy: 5.1244\n",
      "Epoch 7/250\n",
      "39355/39355 [==============================] - 86s 2ms/step - loss: 5.1924 - sparse_categorical_crossentropy: 5.0436\n",
      "Epoch 8/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 5.1173 - sparse_categorical_crossentropy: 4.9593\n",
      "Epoch 9/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 5.0386 - sparse_categorical_crossentropy: 4.8684\n",
      "Epoch 10/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 4.9571 - sparse_categorical_crossentropy: 4.7721\n",
      "Epoch 11/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 4.8701 - sparse_categorical_crossentropy: 4.6671\n",
      "20\n",
      "generating poems:\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never \n",
      " and be is a self and loper of a heart \n",
      " and i i i and mine eye in me \n",
      " and you with the love and my love in me \n",
      " and all the marper of my love to me \n",
      " but \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never live \n",
      " than i you do not so bo lovelyment \n",
      " then i with thee not be to love of moing \n",
      " and so her world o my hards prolinters and \n",
      " nor thou and stord to theted in your fill \n",
      " \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never prove prove \n",
      " will did thou mind graerems where light compest \n",
      " find for which love provering in unseaith hours \n",
      " they pride proceion up thus have heavenly fave \n",
      " but love can twly stew into \n",
      "\n",
      "Epoch 12/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 4.7802 - sparse_categorical_crossentropy: 4.5564\n",
      "Epoch 13/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 4.6792 - sparse_categorical_crossentropy: 4.4312\n",
      "Epoch 14/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 4.5726 - sparse_categorical_crossentropy: 4.2991\n",
      "Epoch 15/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 4.4588 - sparse_categorical_crossentropy: 4.1577\n",
      "Epoch 16/250\n",
      "39355/39355 [==============================] - 92s 2ms/step - loss: 4.3408 - sparse_categorical_crossentropy: 4.0096\n",
      "Epoch 17/250\n",
      "39355/39355 [==============================] - 87s 2ms/step - loss: 4.2254 - sparse_categorical_crossentropy: 3.8642\n",
      "Epoch 18/250\n",
      "39355/39355 [==============================] - 85s 2ms/step - loss: 4.1059 - sparse_categorical_crossentropy: 3.7112\n",
      "Epoch 19/250\n",
      "39355/39355 [==============================] - 85s 2ms/step - loss: 3.9791 - sparse_categorical_crossentropy: 3.5505\n",
      "Epoch 20/250\n",
      "39355/39355 [==============================] - 86s 2ms/step - loss: 3.8479 - sparse_categorical_crossentropy: 3.3843\n",
      "Epoch 21/250\n",
      "39355/39355 [==============================] - 86s 2ms/step - loss: 3.7182 - sparse_categorical_crossentropy: 3.2179\n",
      "20\n",
      "generating poems:\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never shall \n",
      " for all the thing they would you have be \n",
      " and lose her self that i am not ahear \n",
      " and when it is not thy self dost swifty \n",
      " but thou dost less the world which thou shouldst not \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never shall \n",
      " the time and may never loverslyy \n",
      " than dreadful sweet bints shine and spread \n",
      " then with the dead which cunning dly rhyll \n",
      " sweet is the lovely and compiery sp \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never did their view \n",
      "y not guanksthay their accountier remend \n",
      " when find i full full is ad like no begar \n",
      " these rokurpulledise dorrowder then it \n",
      " but can then if i \n",
      "\n",
      "Epoch 22/250\n",
      "39355/39355 [==============================] - 87s 2ms/step - loss: 3.5801 - sparse_categorical_crossentropy: 3.0442\n",
      "Epoch 23/250\n",
      "39355/39355 [==============================] - 87s 2ms/step - loss: 3.4436 - sparse_categorical_crossentropy: 2.8700\n",
      "Epoch 24/250\n",
      "39355/39355 [==============================] - 86s 2ms/step - loss: 3.3003 - sparse_categorical_crossentropy: 2.6893\n",
      "Epoch 25/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 3.1578 - sparse_categorical_crossentropy: 2.5122\n",
      "Epoch 26/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 3.0128 - sparse_categorical_crossentropy: 2.3338\n",
      "Epoch 27/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 2.8694 - sparse_categorical_crossentropy: 2.1606\n",
      "Epoch 28/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 2.7316 - sparse_categorical_crossentropy: 1.9933\n",
      "Epoch 29/250\n",
      "39355/39355 [==============================] - 86s 2ms/step - loss: 2.5927 - sparse_categorical_crossentropy: 1.8316\n",
      "Epoch 30/250\n",
      "39355/39355 [==============================] - 87s 2ms/step - loss: 2.4631 - sparse_categorical_crossentropy: 1.6829\n",
      "Epoch 31/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 2.3362 - sparse_categorical_crossentropy: 1.5376\n",
      "20\n",
      "generating poems:\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but is the fairest in but ornament remain \n",
      " and what a least not love my heart will strew \n",
      " but if it is my heart will be acquain \n",
      " for if i wish that then or else my love \n",
      " \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but then ye swift against a cords with gree \n",
      " and from your glory temptingth to my smart \n",
      " by these even so she or terage far anon \n",
      " blest the numb presented \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " stealing thecked fairest world tomght with rammest \n",
      " both gold with love and pure assaintained be \n",
      "lt myself such starle hadd than made conspireate \n",
      " and feri thoughtswle form and \n",
      "\n",
      "Epoch 32/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 2.2191 - sparse_categorical_crossentropy: 1.4088\n",
      "Epoch 33/250\n",
      "39355/39355 [==============================] - 87s 2ms/step - loss: 2.1037 - sparse_categorical_crossentropy: 1.2825\n",
      "Epoch 34/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 1.9943 - sparse_categorical_crossentropy: 1.1685\n",
      "Epoch 35/250\n",
      "39355/39355 [==============================] - 85s 2ms/step - loss: 1.8855 - sparse_categorical_crossentropy: 1.0571\n",
      "Epoch 36/250\n",
      "39355/39355 [==============================] - 85s 2ms/step - loss: 1.7927 - sparse_categorical_crossentropy: 0.9632\n",
      "Epoch 37/250\n",
      "39355/39355 [==============================] - 86s 2ms/step - loss: 1.7038 - sparse_categorical_crossentropy: 0.8780\n",
      "Epoch 38/250\n",
      "39355/39355 [==============================] - 87s 2ms/step - loss: 1.6215 - sparse_categorical_crossentropy: 0.8035\n",
      "Epoch 39/250\n",
      "39355/39355 [==============================] - 93s 2ms/step - loss: 1.5440 - sparse_categorical_crossentropy: 0.7331\n",
      "Epoch 40/250\n",
      "39355/39355 [==============================] - 93s 2ms/step - loss: 1.4760 - sparse_categorical_crossentropy: 0.6752\n",
      "Epoch 41/250\n",
      "39355/39355 [==============================] - 95s 2ms/step - loss: 1.4097 - sparse_categorical_crossentropy: 0.6176\n",
      "20\n",
      "generating poems:\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should by time decease \n",
      " his tender heir might bear his memory \n",
      " but thou contracted to thine own bright eyes \n",
      " feedst thy lights flame with selfsubst \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should that harpest frome \n",
      " am for my politation foes from thou art \n",
      " but faring thoughts and shung in simple pride \n",
      " to whom my mind when \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might neverwill \n",
      " mine ear that never dothor them rempt \n",
      " here discript from times gives leap her his wrong men \n",
      " love break but my neging all no heaven fill \n",
      " ropnaes i stied in \n",
      "\n",
      "Epoch 42/250\n",
      "39355/39355 [==============================] - 98s 3ms/step - loss: 1.3482 - sparse_categorical_crossentropy: 0.5710\n",
      "Epoch 43/250\n",
      "39355/39355 [==============================] - 101s 3ms/step - loss: 1.2906 - sparse_categorical_crossentropy: 0.5268\n",
      "Epoch 44/250\n",
      "39355/39355 [==============================] - 102s 3ms/step - loss: 1.2386 - sparse_categorical_crossentropy: 0.4883\n",
      "Epoch 45/250\n",
      "39355/39355 [==============================] - 103s 3ms/step - loss: 1.1920 - sparse_categorical_crossentropy: 0.4564\n",
      "Epoch 46/250\n",
      "39355/39355 [==============================] - 101s 3ms/step - loss: 1.1472 - sparse_categorical_crossentropy: 0.4265\n",
      "Epoch 47/250\n",
      "39355/39355 [==============================] - 100s 3ms/step - loss: 1.1109 - sparse_categorical_crossentropy: 0.4040\n",
      "Epoch 48/250\n",
      "39355/39355 [==============================] - 100s 3ms/step - loss: 1.0636 - sparse_categorical_crossentropy: 0.3729\n",
      "Epoch 49/250\n",
      "39355/39355 [==============================] - 101s 3ms/step - loss: 1.0288 - sparse_categorical_crossentropy: 0.3535\n",
      "Epoch 50/250\n",
      "39355/39355 [==============================] - 103s 3ms/step - loss: 0.9971 - sparse_categorical_crossentropy: 0.3361\n",
      "Epoch 51/250\n",
      "39355/39355 [==============================] - 98s 2ms/step - loss: 0.9667 - sparse_categorical_crossentropy: 0.3201\n",
      "20\n",
      "generating poems:\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should by time decease \n",
      " his tender heir might bear his memory \n",
      " but thou contracted to thine own bright eyes \n",
      " feedst thy lights flame with selfsubst \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should by time decease \n",
      " his tender heir might bear his memory \n",
      " but thou contracted to thine own bright eyes \n",
      " feedst thy lights flame with selfsubst \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never suff may why \n",
      " which vain or wo unhase hath seem their hs thee know \n",
      " for fear of juned baim for every state \n",
      " advis seeth my self the will is that earth \n",
      " seed another beautor \n",
      "\n",
      "Epoch 52/250\n",
      "39355/39355 [==============================] - 100s 3ms/step - loss: 0.9365 - sparse_categorical_crossentropy: 0.3027\n",
      "Epoch 53/250\n",
      "39355/39355 [==============================] - 105s 3ms/step - loss: 0.9097 - sparse_categorical_crossentropy: 0.2906\n",
      "Epoch 54/250\n",
      "39355/39355 [==============================] - 107s 3ms/step - loss: 0.8875 - sparse_categorical_crossentropy: 0.2797\n",
      "Epoch 55/250\n",
      "39355/39355 [==============================] - 108s 3ms/step - loss: 0.8618 - sparse_categorical_crossentropy: 0.2658\n",
      "Epoch 56/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 0.8344 - sparse_categorical_crossentropy: 0.2528\n",
      "Epoch 57/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 0.8177 - sparse_categorical_crossentropy: 0.2476\n",
      "Epoch 58/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 0.8104 - sparse_categorical_crossentropy: 0.2414\n",
      "Epoch 59/250\n",
      "39355/39355 [==============================] - 91s 2ms/step - loss: 0.7757 - sparse_categorical_crossentropy: 0.2271\n",
      "Epoch 60/250\n",
      "39355/39355 [==============================] - 90s 2ms/step - loss: 0.7589 - sparse_categorical_crossentropy: 0.2214\n",
      "Epoch 61/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 0.7391 - sparse_categorical_crossentropy: 0.2121\n",
      "20\n",
      "generating poems:\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should by time decease \n",
      " his tender heir might bear his memory \n",
      " but thou contracted to thine own bright eyes \n",
      " feedst thy lights flame with selfsubst \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should all time decound \n",
      " his hordes where weep with famished blot \n",
      " one should i think at the greatersing plain \n",
      " and sigh the nater and one \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never wowing \n",
      " so should that comsec rep stay her st hured thee \n",
      " i lend new than ill near but remainet think \n",
      " where best knows you conwemp them accpect \n",
      "ays they thou dare be the prep \n",
      "\n",
      "Epoch 62/250\n",
      "39355/39355 [==============================] - 91s 2ms/step - loss: 0.7205 - sparse_categorical_crossentropy: 0.2046\n",
      "Epoch 63/250\n",
      "39355/39355 [==============================] - 94s 2ms/step - loss: 0.7016 - sparse_categorical_crossentropy: 0.1958\n",
      "Epoch 64/250\n",
      "39355/39355 [==============================] - 92s 2ms/step - loss: 0.6898 - sparse_categorical_crossentropy: 0.1926\n",
      "Epoch 65/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 0.6743 - sparse_categorical_crossentropy: 0.1860\n",
      "Epoch 66/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 0.6622 - sparse_categorical_crossentropy: 0.1827\n",
      "Epoch 67/250\n",
      "39355/39355 [==============================] - 89s 2ms/step - loss: 0.6489 - sparse_categorical_crossentropy: 0.1770\n",
      "Epoch 68/250\n",
      "39355/39355 [==============================] - 88s 2ms/step - loss: 0.6336 - sparse_categorical_crossentropy: 0.1706\n",
      "Epoch 69/250\n",
      "39355/39355 [==============================] - 86s 2ms/step - loss: 0.6235 - sparse_categorical_crossentropy: 0.1666\n",
      "Epoch 70/250\n",
      "39355/39355 [==============================] - 85s 2ms/step - loss: 0.6079 - sparse_categorical_crossentropy: 0.1609\n",
      "Epoch 71/250\n",
      "39355/39355 [==============================] - 84s 2ms/step - loss: 0.5971 - sparse_categorical_crossentropy: 0.1577\n",
      "20\n",
      "generating poems:\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should by time decease \n",
      " his tender heir might bear his memory \n",
      " but thou contracted to thine own bright eyes \n",
      " feedst thy lights flame with selfsubst \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the riper should by time decease \n",
      " his tender heir might bear his memory \n",
      " but thou contracted to thine own bright eyes \n",
      " feedst thy lights flame with selfsubst \n",
      "\n",
      "seed:  from fairest creatures we desire increase \n",
      " that thereby beautys rose might never\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but me divine whereunith sly away stand \n",
      " where whatswerd upon his came when my part again \n",
      " as we straight upon where thou life some spark \n",
      " being best wilt take this grief will ban only see \n",
      "\n",
      "Epoch 72/250\n",
      "20480/39355 [==============>...............] - ETA: 40s - loss: 0.5814 - sparse_categorical_crossentropy: 0.1477"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-de966f9013ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m model.fit(X, y, batch_size=256, epochs=n_epochs,\n\u001b[0;32m---> 26\u001b[0;31m           callbacks=[print_callback, es_callback, checkpoint_callback])\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LambdaCallback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "n_epochs = 250\n",
    "\n",
    "def on_epoch_end(epoch, _, epochs_split=10):\n",
    "    if epoch % epochs_split == 0 and epoch > 0:\n",
    "        \n",
    "        seed = sp.encode_as_ids(np.random.choice(poems))[:window_size]\n",
    "        \n",
    "        print(len(seed))\n",
    "        \n",
    "        print('generating poems:')\n",
    "        \n",
    "        for temp in [0.25, 0.75, 1.5]:\n",
    "            generate_seq(seed, temperature=temp, use_sample=True)\n",
    "            \n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "es_callback = EarlyStopping(monitor='loss', min_delta=0.01, patience=5, \n",
    "                            verbose=1, mode='auto')\n",
    "\n",
    "filepath=\"model-ckpt-epoch{epoch:08d}.hdf5\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath, save_weights_only=True, period=10)\n",
    "\n",
    "model.fit(X, y, batch_size=256, epochs=n_epochs,\n",
    "          callbacks=[print_callback, es_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_poems(first_line, temps=[1.0]):\n",
    "    \n",
    "    output = ''\n",
    "    \n",
    "    def reverse_formatting(s):\n",
    "        return s.replace('▁', ' ').replace('@', '\\n').replace('<unk>', '')\n",
    "    \n",
    "    seed = sp.encode_as_ids(first_line.lower().replace('\\n', ' @'))    \n",
    "    print('seed: ' + reverse_formatting(first_line))\n",
    "\n",
    "    output += 'seed: ' + reverse_formatting(first_line) + '\\n'\n",
    "  \n",
    "    for temperature in temps:\n",
    "        \n",
    "\n",
    "        result = ''\n",
    "        lines = 1\n",
    "        \n",
    "        in_text = seed.copy()\n",
    "        while len(in_text) < window_size:\n",
    "            in_text = [sp.pad_id()] + in_text\n",
    "            \n",
    "        while lines < 14 and len(result) < 1000:\n",
    "            yhat = model.predict(np.array([in_text[-window_size:]]), verbose=0)\n",
    "            yhat = sample(yhat[0], temperature)\n",
    "            \n",
    "            in_text.append(yhat)\n",
    "            result += (number_to_text([yhat]))\n",
    "\n",
    "            lines = result.count('@')\n",
    "\n",
    "        r_seed = reverse_formatting(number_to_text(seed))\n",
    "        print('temperature:', temperature)\n",
    "        print('generated:\\n' + r_seed + reverse_formatting(result), '\\n')\n",
    "        \n",
    "        output += 'temperature: ' + str(temperature) + '\\n'\n",
    "        output += 'generated:\\n' + r_seed + reverse_formatting(result) + '\\n'\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: from fairest creatures we desire increase\n",
      " that thereby beautys rose might never\n",
      "temperature: 0.25\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but as the thing they would have suvel \n",
      " whereof a lose thee that i do abuse \n",
      " so all the world doth live in doupy thought \n",
      " and my love for they are still with thee \n",
      " and thou art more than thy self dost looking \n",
      " as thou art therefore and my self dost be \n",
      " thou dost be not let me give them to be \n",
      " thou mayst thou art not for my verse to been \n",
      " to make them love to my self ill show \n",
      " and thou art that which i will be dwelled \n",
      " in my great triumphor and thou dost thou use \n",
      " and to the hands of all the world doth please \n",
      " spending on the world which they did shrive \n",
      " \n",
      "\n",
      "temperature: 0.75\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never be \n",
      " the means of my love and darter not thy sits \n",
      " so by that i force but thou dost thou prove \n",
      " mine eye therefore like my self unsest forgil \n",
      " yet be i grounded and past as interer oil \n",
      " yet to be errors of their hands new \n",
      " love to thee i think much more endure for ever \n",
      " but to thy stormb that which doth it doth give \n",
      " that is not for envy or cheather satter \n",
      " no more i love that she with loves worthless worth \n",
      " and for her so fair that thou dostst thee remain \n",
      " great heart she is thy love to say you again \n",
      " then bettered thy the world may scope \n",
      " be by such worth judet that in his lorate be \n",
      " \n",
      "\n",
      "temperature: 1.5\n",
      "generated:\n",
      " from fairest creatures we desire increase \n",
      " that thereby beautys rose might never die \n",
      " but still that still and compough can dalace \n",
      " make while eyes farsand ar suffer eyes thence \n",
      " i be i feel the faults are of thine of thine \n",
      " where can this seem loveless sl best would know \n",
      " love loth pass him bliner hands to all my wit \n",
      " loot flbes healcked b gave upon vain more pass \n",
      " like the movenatures new dined never crown \n",
      " looks fresh and friend so w lod thought never ill \n",
      " anteregedli golden and ha her shall make my mind \n",
      " for that which fairest he alive he speak to seem \n",
      " so those the shafe of thee should heaven love can eyes \n",
      " beself therefore i love should pleasance make \n",
      " hardhere re mer deep mightnd forgot to pain lies \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model-ckpt-epoch00000030.hdf5')\n",
    "\n",
    "prompt = \"from fairest creatures we desire increase\\n that thereby beautys rose might never\"\n",
    "tlist = [0.25, 0.75, 1.5]\n",
    "\n",
    "for _ in range(1):\n",
    "    write_poems(prompt, temps=tlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[525.   7.  81. 103.  17. 301. 994.  20. 260. 142.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-6cc6b513c528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    ce = -(1.0/y_true.shape[0]) * np.sum(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "    perplexity = np.exp(ce)\n",
    "    return perplexity\n",
    "\n",
    "print(y[:10])\n",
    "y_pred = model.predict(X)\n",
    "yy = y.astype(int)\n",
    "yy = np.eye(np.max(yy) + 1)[yy]\n",
    "\n",
    "z = np.zeros((yy.shape[0], 1000))\n",
    "z[:,:-1] = yy\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(z.shape)\n",
    "\n",
    "print(perplexity(z, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
